#!/usr/bin/env python3
"""
Complete realistic fact-checking system.

This integrates claim preprocessing with the fact-checking pipeline
to handle complex YouTube-style claims effectively.
"""

import asyncio
import json
import tempfile
import sqlite3
from pathlib import Path
from datetime import datetime, timezone

# Add the project root to path
import sys
sys.path.insert(0, str(Path(__file__).parent))

from debate_claim_extractor.fact_checking.fact_models import (
    FactCheckResult, VerificationSource, VerificationStatus, 
    AggregatedVerification, FactCheckConfig, SourceType
)
from debate_claim_extractor.fact_checking.services.local_service import LocalFactCheckService
from debate_claim_extractor.fact_checking.fact_pipeline import FactVerificationPipeline
from debate_claim_extractor.pipeline.models import Claim, ClaimType


class EnhancedLocalService(LocalFactCheckService):
    """Enhanced local service with better test data support."""
    
    async def populate_test_data(self, test_data: list):
        """Populate database with test data."""
        try:
            with sqlite3.connect(self.database_path) as conn:
                cursor = conn.cursor()
                
                for entry in test_data:
                    # Normalize the text for better matching
                    normalized = entry["claim"].lower().strip()
                    
                    cursor.execute("""
                        INSERT OR REPLACE INTO fact_checks 
                        (claim_text, normalized_text, verification_status, verification_score,
                         source_name, source_url, explanation, credibility_score)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        entry["claim"],
                        normalized,
                        entry["status"],
                        entry["confidence"],
                        entry["source"],
                        entry["url"],
                        entry.get("explanation", f"Fact-check from {entry['source']}"),
                        entry.get("credibility", 0.8)
                    ))
                
                conn.commit()
                self.logger.info(f"Added {len(test_data)} fact-check entries to database")
                
        except Exception as e:
            self.logger.error(f"Failed to populate test data: {e}")


class SmartClaimProcessor:
    """Intelligently process and simplify complex claims for fact-checking."""
    
    def __init__(self):
        self.patterns = {
            # Physics and science patterns
            'causality': [
                ("causality", "Causality is a fundamental principle in physics"),
                ("determinism", "Physical systems follow deterministic laws"),
                ("predetermined", "Physical systems follow deterministic laws"),
                ("quantum.*uncertainty", "Quantum mechanics involves fundamental uncertainty"),
                ("stochastic", "Random processes exist in nature"),
                ("randomness", "Random processes exist in nature"),
                ("unpredictability", "Random processes exist in nature"),
            ],
            
            # Philosophy patterns  
            'philosophy': [
                ("free will.*no|no.*free will", "Determinism is incompatible with free will"),
                ("experience.*decision", "Past experiences influence decision making"),
                ("antecedent", "All events have prior causes"),
            ],
            
            # Psychology and behavior
            'psychology': [
                ("10,?000 hours", "10,000 hours of practice leads to expertise"),
                ("training.*reflex", "Training creates reflexive responses"),
                ("neural.*pathway", "Neural pathways can be trained"),
                ("experience.*improve", "Experience leads to skill improvement"),
                ("joke.*experience", "Comedians improve through experience"),
            ],
            
            # Statistics and probability
            'statistics': [
                ("statistically.*chance", "Statistical patterns can predict outcomes"),
                ("data.*predict", "Historical data can predict future outcomes"),
            ]
        }
    
    def extract_checkable_claims(self, claim_text: str) -> list:
        """Extract checkable factual claims from complex text."""
        import re
        
        text_lower = claim_text.lower()
        extracted = []
        
        for category, patterns in self.patterns.items():
            for pattern, fact_claim in patterns:
                if re.search(pattern, text_lower):
                    extracted.append(fact_claim)
        
        # Remove duplicates while preserving order
        seen = set()
        unique_extracted = []
        for claim in extracted:
            if claim not in seen:
                seen.add(claim)
                unique_extracted.append(claim)
        
        return unique_extracted
    
    def process_claim_for_fact_checking(self, claim: Claim) -> list:
        """Process a complex claim into fact-checkable components."""
        # Extract checkable facts
        checkable_facts = self.extract_checkable_claims(claim.text)
        
        if not checkable_facts:
            # If no patterns match, return original claim
            return [claim]
        
        # Create new Claim objects for each extracted fact
        processed_claims = []
        for fact in checkable_facts:
            processed_claim = Claim(
                type=claim.type,
                text=fact,
                speaker=claim.speaker,
                sentence_id=claim.sentence_id,
                turn_id=claim.turn_id,
                char_start=claim.char_start,
                char_end=claim.char_end,
                confidence=min(claim.confidence * 0.9, 0.95),  # Slightly lower confidence
                context=f"Extracted from: {claim.text[:100]}..."
            )
            processed_claims.append(processed_claim)
        
        return processed_claims


async def test_with_google_api():
    """Test with Google Fact Check API if available."""
    import os
    
    api_key = os.getenv('GOOGLE_FACT_CHECK_API_KEY')
    if not api_key:
        print("‚ö†Ô∏è  Google API key not found. Set GOOGLE_FACT_CHECK_API_KEY to test with real API.")
        return False
    
    print("üåê Testing with Google Fact Check API")
    print("=" * 60)
    
    from debate_claim_extractor.fact_checking.services.google_service import GoogleFactCheckService
    
    google_service = GoogleFactCheckService(api_key=api_key)
    
    # Test with some factual claims that might have fact-checks
    test_claims = [
        "Climate change is caused by human activities",
        "Vaccines are safe and effective", 
        "The Earth is approximately 4.5 billion years old",
    ]
    
    for claim_text in test_claims:
        print(f"üîç Testing: {claim_text}")
        
        try:
            result = await google_service.verify_claim(claim_text)
            
            if result:
                print(f"   ‚úÖ Status: {result.status.value}")
                print(f"   üìä Confidence: {result.confidence:.2f}")
                if result.sources:
                    print(f"   üìö Sources: {len(result.sources)}")
                    for source in result.sources[:2]:
                        print(f"      - {source.name}")
            else:
                print(f"   ‚ùì No fact-check data found")
                
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
        
        print()
    
    return True


async def main():
    """Demonstrate realistic fact-checking with complex claims."""
    print("üéØ REALISTIC FACT-CHECKING DEMONSTRATION")
    print("Using complex YouTube-style claims")
    print("=" * 70)
    
    # Load sample claims if available
    sample_claims = []
    try:
        with open('sample_claims.json', 'r') as f:
            data = json.load(f)
            sample_claims = data['claims'][:5]  # First 5 claims
            print(f"üìÑ Loaded {len(sample_claims)} sample claims")
    except FileNotFoundError:
        print("üìÑ Using hardcoded test claims (sample_claims.json not found)")
        sample_claims = [
            {
                "type": "causal",
                "text": "so if you take it to its logical conclusion then there is no free will because everything is predetermined by things that everything has an antecedent",
                "speaker": "CHARLES",
                "sentence_id": "test_1",
                "turn_id": 1,
                "char_start": 0,
                "char_end": 100,
                "confidence": 0.65
            },
            {
                "type": "factual", 
                "text": "there is also stochastic uncertainty in the universe it's built in there's randomness there's unpredictability",
                "speaker": "CHARLES",
                "sentence_id": "test_2",
                "turn_id": 2, 
                "char_start": 0,
                "char_end": 100,
                "confidence": 0.70
            }
        ]
    
    print("\nüî¨ Step 1: Claim Preprocessing")
    print("=" * 40)
    
    processor = SmartClaimProcessor()
    all_processed_claims = []
    
    for i, claim_data in enumerate(sample_claims):
        claim = Claim(**claim_data)
        print(f"\nüß† Original claim {i+1}:")
        print(f"   {claim.text[:100]}...")
        
        processed = processor.process_claim_for_fact_checking(claim)
        print(f"üí° Extracted {len(processed)} checkable claims:")
        
        for j, proc_claim in enumerate(processed):
            print(f"   {j+1}. {proc_claim.text}")
            all_processed_claims.append(proc_claim)
    
    print(f"\nüìä Total checkable claims: {len(all_processed_claims)}")
    
    print("\nüîç Step 2: Fact-Checking")  
    print("=" * 40)
    
    # Set up enhanced local database
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
        temp_db = f.name
    
    try:
        service = EnhancedLocalService(database_path=temp_db)
        
        # Enhanced fact-check database
        fact_database = [
            {
                "claim": "Causality is a fundamental principle in physics",
                "status": "verified_true",
                "confidence": 0.95,
                "source": "Physics Encyclopedia",
                "url": "https://physics.org/causality",
                "explanation": "Causality is indeed a fundamental principle in physics"
            },
            {
                "claim": "Physical systems follow deterministic laws",
                "status": "likely_true",
                "confidence": 0.85,
                "source": "Stanford Encyclopedia of Philosophy", 
                "url": "https://plato.stanford.edu/determinism",
                "explanation": "Classical physics is largely deterministic, but quantum mechanics introduces probabilistic elements"
            },
            {
                "claim": "Quantum mechanics involves fundamental uncertainty",
                "status": "verified_true",
                "confidence": 0.95,
                "source": "Quantum Physics Journal",
                "url": "https://quantum.org/uncertainty-principle",
                "explanation": "Heisenberg uncertainty principle is fundamental to quantum mechanics"
            },
            {
                "claim": "Random processes exist in nature",
                "status": "verified_true", 
                "confidence": 0.90,
                "source": "Nature Scientific Journal",
                "url": "https://nature.com/quantum-randomness",
                "explanation": "Quantum mechanical processes exhibit true randomness"
            },
            {
                "claim": "Determinism is incompatible with free will",
                "status": "mixed",
                "confidence": 0.60,
                "source": "Philosophy Database",
                "url": "https://philosophy.org/free-will-determinism",
                "explanation": "This is an ongoing philosophical debate with arguments on both sides"
            },
            {
                "claim": "All events have prior causes",
                "status": "likely_true",
                "confidence": 0.80,
                "source": "Metaphysics Research",
                "url": "https://metaphysics.org/causation",
                "explanation": "The principle of causation is widely accepted in science and philosophy"
            },
            {
                "claim": "10,000 hours of practice leads to expertise",
                "status": "mixed",
                "confidence": 0.65,
                "source": "Skills Research Institute",
                "url": "https://skills.org/deliberate-practice",
                "explanation": "The 10,000 hour rule is oversimplified; quality of practice matters more than quantity"
            }
        ]
        
        await service.populate_test_data(fact_database)
        
        # Create pipeline
        config = FactCheckConfig(timeout_seconds=30)
        pipeline = FactVerificationPipeline(config=config)
        pipeline.services = [service]
        
        print(f"üî¨ Fact-checking {len(all_processed_claims)} processed claims...")
        
        verified_count = 0
        results = []
        
        for claim in all_processed_claims:
            result = await pipeline.verify_claim(claim)
            results.append(result)
            
            print(f"\nüîç Checking: {claim.text}")
            
            if result.overall_status != VerificationStatus.UNVERIFIED:
                verified_count += 1
                print(f"   ‚úÖ {result.overall_status.value}")
                print(f"   üìä Confidence: {result.confidence:.2f}")
                if result.primary_sources:
                    print(f"   üìö Source: {result.primary_sources[0].name}")
            else:
                print(f"   ‚ùì No verification data found")
        
        print("\nüìà Step 3: Results Summary")
        print("=" * 40)
        print(f"Total processed claims: {len(all_processed_claims)}")
        print(f"Claims with verification: {verified_count}")
        print(f"Verification rate: {verified_count/len(all_processed_claims)*100:.1f}%")
        
        # Test Google API if available
        await test_with_google_api()
        
        print("\n‚ú® SUCCESS!")
        print("=" * 40)
        print("üéØ The realistic fact-checking system:")
        print("   ‚úÖ Successfully preprocesses complex claims")
        print("   ‚úÖ Extracts fact-checkable components")
        print("   ‚úÖ Verifies claims against knowledge base")
        print("   ‚úÖ Provides confidence scores and sources")
        
        print("\nüí° Next Steps:")
        print("   1. Get Google Fact Check API key for broader coverage")
        print("   2. Expand the local fact database for your domain")
        print("   3. Integrate preprocessing into main pipeline")
        print("   4. Add more sophisticated claim extraction patterns")
        
    finally:
        # Clean up
        import os
        if os.path.exists(temp_db):
            os.unlink(temp_db)


if __name__ == "__main__":
    asyncio.run(main())
